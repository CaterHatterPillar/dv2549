\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left

\usepackage{color}
\usepackage{float}
\usepackage{mdwlist}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{footmisc}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{listings}

% Consider inserting:
%\usepackage{kpfonts}

\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract

\definecolor{color1}{RGB}{0,0,0} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

\newlength{\tocsep} 
\setlength\tocsep{1.5pc} % Sets the indentation of the sections in the table of contents
\setcounter{tocdepth}{3} % Show only three levels in the table of contents section: sections, subsections and subsubsections

\lstset { 
	language=C,
	tabsize=2,
	backgroundcolor=\color{black!5},
	basicstyle=\footnotesize,
}

\JournalInfo{\today} % Journal information
\Archive{Unpublished} % Additional notes (e.g. copyright, DOI, review/research article)
\PaperTitle{Emulated~GPGPU~Kernels\\A~Study~into~Performance} % Article title
\Authors{Eric~Nilsson} % Authors
\affiliation{EricNNilsson@gmail.com}
%\affiliation{*\textit{Corresponding author}: john@smith.com} % Corresponding author
\Keywords{GPGPU, GPU,  Simulation, Emulation, DirectCompute, WARP} % Keywords - if you don't want any simply remove all the text between the curly brackets
\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

% ABSTRACT
\Abstract{
Emulation of \textit{GPU}-kernels on the \textit{CPU} is common for the purposes of debugging or profiling, but also in situations where hardware implementations are unavailable, such as server-side applications\footref{ftn:warpguide}. When performing such emulation, one may experience severe performance loss due to the architectural differences in-between the two target platforms. This study examines the performance of such emulated kernels, by analyzing three driver types from the \textit{DirectX}-framework using \textit{DirectCompute}, amongst which is the high speed software~rasterizer Microsoft~\textit{WARP}. The performance of \textit{WARP} is compared to that of traditional \textit{GPU}~hardware acceleration and the standard driver for software~rasterization - the Reference~Device~Driver.\\
Results demonstrate a major performance boost when compared to that of software~rasterization using the Reference~Device~Driver. Thus, this study reasons that performance losses traditionally obstructing \textit{GPU}-kernel emulation may be amended sufficiently by technologies, such as Microsoft~\textit{WARP}, to the degree that such emulation can be considered viable for use in retail applications.\\
As such, the hypothesis suggested in this document may be summarized as follows:
\quote{\textit{The performance-impaired emulation of a GPU-kernel may be amended by using high speed software~rasterizers, such as Microsoft~WARP.}}
% \textit{The performance of an emulated GPGPU-kernel on a CPU may have it’s performance substantially improved in exchange for some computational precision.}
%^ Not a valid hypothesis. No sources indicate that WARP has lesser precision.
% Background	(what)
%	Vilket sammanhang utgör studiens bakgrund?
% Challenge		(why)
%	Vilka utmaningar omfattar studien?
% Approach		(how)
%	Vilken ansats tillämpas i studien?
% Results 		(what)
%	Vilka resultat gav studien?
}

\begin{document}
\flushbottom % Makes all text pages the same height
\maketitle % Print the title and abstract box
\thispagestyle{empty} % Removes page numbering from the first page

% INTRODUCTION
\section*{Introduction} % The \section*{} command stops section numbering
\addcontentsline{toc}{section}{\hspace*{-\tocsep}Introduction} % Adds this section to the table of contents with negative horizontal space equal to the indent for the numbered sections
\label{sec:introduction}
% Background and Challenge
%	Vilket sammanhang utgör studiens bakgrund?
%	Vilka utmaningar omfattar studien?
When developing \textit{GPU}-kernels, relatively small modifications in code may induce large deviations in performance due to massively parallelized instruction sets and architectural differences in-
between on-chip hardware\footnote{See Performance~Considerations by Kirk~\&~Hwu\cite[ch.~6]{Kirk:2010:PMP:1841511} for an analyis on the volatility of \textit{GPGPU}-performance.}. The increased utilization of complex \textit{GPGPU}-kernels has brought forth the need of more extensive debugging- and profiling-possibilities involving access of data that may be hard to retrieve from hardware. Therefore, it may be desirable for the developer to be able to view the data being computed on the graphics card - a possibility often limited in terms of \textit{GPGPU}-technologies, possibly due to architectural differences in-between chip manufacturers.\\
% Approach and Result
%	Vilken ansats tillämpas i studien?
A preferred solution to this problem has been to emulate such \textit{GPU}-kernels on the \textit{CPU}\footnote{\label{ftn:drivertypes}Microsoft's reference on \textit{DirectX}~Driver~Types: \url{http://bit.ly/1b63NiX}. Retrieved: 21-10-2013.}, such as described by Kerr et al.\cite[p.~416-419]{Hwu:2011:GCG:2103614} concerning the implementation of the \textit{GPU~Ocelot} compilation framework\footnote{\label{ftn:ocelot}\textit{GPU}~Ocelot: \url{http://b.gatech.edu/1a489L1}. Retrieved 22-10-2013.}, often in exchange for substantial performance-losses. Other resons to emulate \textit{GPU}-kernels may concern pre-silicon development - that is, development for hardware not yet existant, when hardware is busy, or otherwize unavailable\footnote{\label{ftn:warpguide}Microsoft's reference on \textit{WARP}: \url{http://bit.ly/19hiwrZ}. Retrieved: 21-10-2013.}. This study comprises an investigation into the performance of software emulation of hardware accelerated \textit{GPGPU}-kernels, by the means of analyzing several software rasterizers.\\
\\
Furthermore, this material concerns inquiry into the \textit{DirectCompute}-framework on the \textit{Windows}-platform, analyzing the performance of a \textit{GPGPU}-kernel on-chip, using the \textit{DirectX} standard software rasterizer, and utilizing the \textit{DirectX~11.1}-addition Microsoft~\textit{WARP}\footnote{\textit{Windows~Advanced~Rasterization~Platform}.}-technology - which promises high-speed software emulation\footref{ftn:warpguide}. \\
\\
%	Vilka resultat gav studien?
This article concludes that the performance losses inflicted by such emulation may be reduced enough for that emulation to be considered feasable for retail use, as originally proposed by Microsoft\footref{ftn:warpguide}. Thus, this study proposes use of Microsoft~\textit{WARP}-technology in industry rasterization if graphics~hardware is unavailable, not sufficient, or busy.\\
\\
% Outline and Conclusion
As such, the study concerns the fields of simulation, emulation and \textit{GPU}-technologies - respectively, with the purpose of facilitating debugging and profiling of \textit{GPU}-kernels, whilst maintaining acceptable performance. \\
The remainder of this document presents the method and process to acquire the data used,  the technologies using which it has been acquired, the results in and of their own, the conclusions based off the results and finally; the author's personal reflections surrounding future~work in the area along with propositions of further study.

% CONTRIBUTION
\section{Contribution}
\label{sec:contribution}
% Introduction
%	Vilka principer, modeller, metoder och teknologier omfattar studiens design?

% CONTRIBUTION - METHOD
\subsection{Object~of~Study}
\label{sec:contribution:objectofstudy}
Due to the nature of the experiment, it is important that the Object~of~Study is measurable and deterministic. For the purpose of this study, the data computed corresponds to a square matrix~multiplication, since such an operation is highly parallelizable, as demonstrated by Kirk~\&~Hwu\cite[ch.~3]{Kirk:2010:PMP:1841511}. Additionally, verifying the result of such an operation is trivial, and potential losses in computational precision may be computed from the expected data-type. The operation was therefore considered suitable for the purpose of this experiment.\\
\\
The dimension $200x200$ was selected for the respective matrices as it is big enough to execute efficiently on the \textit{GPU}, but yet reasonably sized to keep measurements collected by the means of emulation comparable to the hardware~accelerated reference case. \\
Throughout this material, the compiled data will be referred to as $AB=C$, and thus make out the Object of this experiment.

\subsection{Method}
\label{sec:contribution:method}
In order to establish the Object~of~Study, $AB=C$, the experiment utilizes \textit{GPGPU}-kernels using which the result is calculated, in it’s entirety, in aforementioned kernel using some target Subject (see Section~\ref{sec:contribution:Subjectofstudy}). The experiment is devised of the following approximate steps in order to compile the Object~of~Study $AB=C$:
\begin{enumerate*}
	\item Randomize two matrices $A$ \& $B$ using desired data-type.
	\item Establish the product-matrix $AB=Ref$. The resulting matrix will be used as a reference matrix to verify the final result.
	\item Start a synchronized high-precision timer.
	\item Dispatch \textit{GPU}-kernel calculating the product matrix $AB=C$.
	\item Stop the timer once the kernel has finished execution.
	\item Establish possible deviation in-between resulting matrix $C$ and previously established matrix $Ref$.
\end{enumerate*}
The process described above make out the Method of this study.

\subsection{Subjects~of~Study}
\label{sec:contribution:Subjectofstudy}
The \textit{GPU}-kernels described in Section~\ref{sec:contribution:method} are comprised of \textit{HLSL}-syntax and are compiled \& executed using Microsoft~\textit{DirectCompute}. These kernels are run using three types of acceleration~technologies with varying strategies of \textit{GPU}-kernel emulation. These are comprised of the following:
\paragraph{Hardware-Acceleration~(GPU)}
	The execution of a \textit{DirectCompute}-kernel on a graphics card. This is the common case, and involves no emulation of the kernel. Thus, this case will act as a reference for the emulated Subjects.\\
	During hardware~acceleration on the \textit{GPU}, one may expect high performance.
\paragraph{Software~Rasterization~(CPU)}
	The emulated execution of a \textit{DirectCompute}-kernel using the \textit{DirectX}~Reference~Device~Driver.\\
The Reference~Driver was developed for the purpose of testing and debugging, and is - although it does support some \textit{CPU}-optimizations - not intended to be used in retail applications\footref{ftn:drivertypes}.\\
	As the Reference~Driver is designed for the purpose of accuracy, rather than speed, one may expect poor performance.
\paragraph{Windows~Advanced~Rasterization~Platform~(CPU)}
	The emulated execution of a \textit{DirectCompute}-kernel using a special software rasterizer devised by Microsoft in their latest revision of the \textit{DirectX}-framework.\\
	The driver is based off the \textit{DirectX}~Reference~Driver and uses thread pooling to distribute tasks efficiently on the \textit{CPU}, along with grouping execution in batches for optimum performance. Microsoft describes \textit{WARP} as a high-performance software~rasterizer, and recommends using the driver for retail applications, such as casual~games\footref{ftn:warpguide}.\\
As there are, as of yet, few studies performed on Microsoft~\textit{WARP}; expectations are unclear, but the driver is expected to perform better than standard software rasterization.\\

\noindent
These three \textit{DirectX} driver-types make out the Subjects of this study.

\subsection{Kernels}
\label{sec:contribution:kernels}
In addition to the Subject drivers mentioned in Section~\ref{sec:contribution:Subjectofstudy}, two kernels with varying lavel of optimization are examined. These kernels have been implemented in accordance to the \textit{CUDA}-kernels as described by Kirk~\&~Hwu\cite[p.~67, p.~87]{Kirk:2010:PMP:1841511}.\\
The kernels are presented below.
\paragraph{Matrix~mult.~w.~Thread~Blocks}
	A kernel producing $AB=C$ from two given matrices, writing back $C$ for further analysis.\\
	The kernel is executed with one thread for each element in the square matrices, and likewize each produce a lone element of the resulting matrix.\\
	Execution is performed in blocks of $16x16$ threads since this was the block dimension, out of samples $8$, $16$, and $32$, that performed optimally whilst hardware~accelerated on the system described in Section~\ref{sec:contribution:equipment}.  \\
	This kernel will be referred to as the Basic~Kernel throughout this material.
\paragraph{Matrix~mult.~w.~Thread~Blocks~\&~Shared~Memory}
	Similar to the previous kernel, but further optimized to utilize \textit{shared~memory} in order to reduce time-consuming reading of \textit{global~memory}, as presented by Kirk~\&~Hwu\cite[p.~77-93]{Kirk:2010:PMP:1841511}.\\
		Stratton et al.\cite[p.~1-3]{Stratton:2008:MEI:1485701.1485703} instructs that the \textit{CUDA}~\textit{GPGPU}-model may be applied onto multicore \textit{CPU}s, including locality-wize execution of logical thread-blocks (all threads in a block limited to a single core), with the utilization of \textit{local}- and \textit{shared}-memory approximately corresponding to a core's \textit{L1}-cache. Hence, the kernel is presented as a scenario due to the preconditions of \textit{WARP} - stating that a kernel optimized for \textit{GPU}-execution is likewize optimized for execution with \textit{WARP}\footref{ftn:warpguide}. Thus, we investigate a more optimized kernel to see whether or not this behaviour may be replicated in the experiment.\\
	This kernel will be referred to as the Tiled~Kernel throughout this material.\\

\noindent
Furthermore, aforementioned kernels both support integer- and floating-point precision.\\
These kernels are attached, in their entirety, under Appendix.

% CONTRIBUTION - TECHNOLOGIES
\subsection{Tools}
\label{sec:contribution:tools}
The experiment process has been subdivided into three major components, all of which use Microsoft~\textit{Visual~Studio~2012} for compilation. These are presented below.

\paragraph{matrixgen}
Denotes a utility developed to generate matrices of different dimensions and data-types. Furthermore, \textit{matrixgen} compiles the reference matrix $Ref$ used when comparing the result returned from the \textit{DirectCompute}-dispatch described in the next paragraph. \\
\textit{matrixgen} is written in \texttt{C++} and utilizes \texttt{C++~AMP} to generate and multiply matrices $A$~\&~$B$ into product matrix $Ref$. In order to achieve random values in a \texttt{C++~AMP}-kernel the solution includes the random number generator-library \texttt{C++~AMP~RNG}.\\
As \textit{matrixgen} utilizes Microsoft~\texttt{C++~AMP}-technology, \textit{Windows~7} or later is required.

\paragraph{experiment}
Making out the primary component of the study, \textit{experiment} uses \textit{DirectCompute} to compile the product matrix $C$ from the matrices $A$~\&~$B$ generated by \textit{matrixgen}. The application outputs data surrounding the execution of said kernel, such as it's execution time in milliseconds, to an intermediate file.\\
\textit{experiment} is written in \texttt{C++} with it's respective \textit{DirectCompute}-kernels written in \texttt{HLSL}-syntax.\\
As \textit{experiment} is developed using the \textit{Windows~8~SDK}, \textit{Windows~8.0} or later is required. Furthermore, \textit{experiment} requires a \textit{DirectX~11.0}- or \textit{DirectX~11.1}-compatible graphics card.

\paragraph{analytics}
\textit{analytics} is a utility developed to compose data surrounding possible precisional deviations in-between matrices $C$~\&~$Ref$. \textit{analytics} compiles the minimum- and maximum-deviation encountered, as well as to calculate the standard deviation of said precisional deviation. In turn, \textit{analytics} outputs this information to an intermediate file.\\
\textit{analytics} is written in \texttt{C++}.\\
\\
\noindent
These three applications are, in turn, run as subprocesses in a script specifying the various configurations and number of times to run each program. This script, written in \textit{Python}, then compiles the assorted results of these applications and outputs a range of files suitably formatted for interpretation by \textit{Gnuplot}.\\
\\
The source code manufactured for the sake of this study is freely available via \textit{GitHub}\footnote{\label{ftn:github}\textit{GitHub}~Repository:~\url{http://bit.ly/1c4wd20}. Retrieved: 21-10-2013.}, along with a guide on how to compile and run the solution in order to replicate the experiment. Furthermore, the complete results collected and used throughout this study is also available for download, and may be acquired for further analysis.

\subsection{Equipment}
\label{sec:contribution:equipment}
The results presented in this study is gathered from experiments performed on a system with the following specifications:
\begin{description*}
	\item[CPU]	Intel Q9550 Quad Core 2.83GHz
	\item[GPU]	ATI Radeon HD 5800
	\item[OS]	Windows 8.0
\end{description*}
This system setup was selected for use, for the purpose of this study, as Microsoft claims that the \textit{WARP}~driver performs best on modern quad-core \textit{CPU}s\footref{ftn:warpguide}.

\subsection{Process~of~Study}
\label{sec:contribution:processofstudy}
For the purpose of this study, the Object~of~Study - being $200x200$ matrices - were randomized with numbers in-between zero and ten. The product matrix of these matrices was then computed 100 times for each configuration. In this way, the Basic~Kernel was run with each Subject~of~Study - being Hardware~Acceleration, Software~Rasterization and \textit{WARP} - respectively, likewize as with the Tiled~Kernel. For each execution, data surrounding the dispatch-time of each kernel (meaning the time taken to execute corresponding kernel, regardless of program initialization.) was garnered along with precision-wize deviational data.\\
The process described above was then repeated for Integer- and Floating~Point-precision.\\

\noindent
The measurements gathered from these executions make out the Results presented in this study.

% CONTRIBUTION - RESULTS
\subsection{Results}
\label{sec:contribution:results}
Based off the average of the collected execution times described in Section~\ref{sec:contribution:processofstudy}; results indicate an improvement in the performance of the kernels when using Microsoft~\textit{WARP}, compared to the performance of the \textit{DirectX}~Reference~Device~Driver from which \textit{WARP} is derived.\\
Table~\ref{tab:contribution:results:summaryint} demonstrates a performance gain with the Hardware~Accelerated Subject when utilizing \textit{shared~memory} amongst blocks; with varying results for the other Subjects - either increasing or decreasing execution time (see Table~\ref{tab:contribution:results:summaryfloat}).

\begin{table}[hbt]
\begin{center}
\begin{tabular}{r|r|r|r|}
	\cline{2-3}
							& \multicolumn{1}{|c|}{\textbf{BASIC}} & \multicolumn{1}{|c|}{\textbf{TILED}}	\\ \hline
	\multicolumn{1}{|l|}{\textbf{HARD}}	& $1.16$			& $0.24$ 	& $-79.3\%$    					\\ \hline
	\multicolumn{1}{|l|}{\textbf{SOFT}}	& $11610.02$		& $9866.40$	& $-15.0\%$     					\\ \hline
	\multicolumn{1}{|l|}{\textbf{WARP}}	& $15.31$			& $18.97$	& $+23.9\%$     					\\ \hline
\end{tabular}
\end{center}
\caption{Average execution time in milliseconds of a $200x200$ integer matrix multiplication.}
\label{tab:contribution:results:summaryint}
\end{table}

\begin{table}[hbt]
\begin{center}
\begin{tabular}{r|r|r|r|}
	\cline{2-3}
							& \multicolumn{1}{|c|}{\textbf{BASIC}} & \multicolumn{1}{|c|}{\textbf{TILED}}	\\ \hline
	\multicolumn{1}{|l|}{\textbf{HARD}}	& $0.77$			& $0.22$		& $-71.4\%$    				\\ \hline
	\multicolumn{1}{|l|}{\textbf{SOFT}}	& $10247.03$		& $10909.88$	& $+6.5\%$     				\\ \hline
	\multicolumn{1}{|l|}{\textbf{WARP}}	& $14.08$			& $17.44$		& $+23.9\%$    				\\ \hline
\end{tabular}
\end{center}
\caption{Average execution time in milliseconds of a $200x200$ floating point matrix multiplication.}
\label{tab:contribution:results:summaryfloat}
\end{table}

\noindent
Using both integer- and floating~point-precision, the performance of \textit{WARP} is impaired by the kernel utilizing \textit{shared~memory} according to the data presented in Tables \ref{tab:contribution:results:summaryint}~\&~\ref{tab:contribution:results:summaryfloat}.\\
In Microsoft's guide on \textit{WARP}\footref{ftn:warpguide}, the author claims that an application, if tuned to run efficiently on hardware, will run efficiently on \textit{WARP} - and vice versa. However, the data collected for this study rather indicates an increase in execution time of $23.9\%$, independant of precision, even though the same kernel accelerates the hardware~accelerated Subject by roughly $70\%$. The floating~point scenario of this effect is visualized in Figure~\ref{fig:contribution:results:warp:msswarp}.

\begin{figure}[htb]
\begin{center}
	\resizebox{ \columnwidth }{!}{\input{msswarp}}
	\caption{\textit{WARP} execution time with float-precision for the Basic- and Tiled-kernel, with visualized mean and standard deviations. Values outside of their respective standard deviations have been clipped for the sake of clarity.}
	\label{fig:contribution:results:warp:msswarp}
\end{center}
\end{figure}

\noindent
Integer~precision calculation showed no sign of precisonal loss whatsoever. Meanwhile, all floating~point-experiments experienced an equal average loss of computational precision. However, the data collected indicates no divergence in the precisional loss of respective Subject. The average deviations in precision experienced equally with each configuration, in relation to the $Ref$-matrix descibed in Section~\ref{sec:contribution:method}, are presented in Table~\ref{tab:contribution:results:avgprecision}.
\label{sec:contribution:results:computationalprecision}
\begin{table}[hbt]
\begin{center}
	\begin{tabular}{|r|r|r|}
		\hline
		\textbf{Minimum} 	& \textbf{Maximum} 	& \textbf{Standard} 	\\ \hline
		0.0     			& ~0.01   			& ~0.0025            		\\ \hline
	\end{tabular}
\caption {Average precisional deviations in floating~point-operations for all Subjects.}
\label{tab:contribution:results:avgprecision}
\end{center}
\end{table}

\noindent
These results were expected as \textit{WARP} conforms to the precision requirements of the \textit{Direct3D~10}-~and~\textit{10.1}-specification\footref{ftn:warpguide}. See Microsoft's documentation on Floating-point Rules\footnote{Microsoft's reference on Floating-Point~Rules:~\url{http://bit.ly/1bOQnZu}. Retrieved 21-10-2013.} for more information surrounding floating~point-precision in the \textit{Direct3D}-framework.

% Contribution
%	Vilka empiriska resultat erhölls vid experimentdesignens implementation?
% Conclusion
% ...for each segment brought up under Contribution.

% CONCLUSION
\section{Conclusion}
\label{sec:conclusion}
Based off the results presented in Section~\ref{sec:contribution:results}, using \textit{WARP} to emulate the kernels presented in this study has magnitudes greater performance than if one were to apply the \textit{DirectX}~Reference~Device~Driver in the same manner. Hence, if one were to compare the execution of \textit{WARP}~\&~the~Reference~Device~Driver side-by-side, and assume the same area of application, \textit{WARP} is superior in terms of execution time - assuming the same preconditions as those presented in this material.\\
However, keeping in mind the major performance improvements offered by Microsoft~\textit{WARP}, it is important to consider that the two may be appropriate for different purposes. The \textit{DirectX}~Reference~Device~Driver is primarily proposed by Microsoft as a debugging-/pre-silicon-development tool, whereas \textit{WARP} is intended for use in a broader sense\footref{ftn:warpguide} - such as to render graphics for casual games - in addition to debugging and error-profiling purposes.\\
This calls for further inquiry into what the flaws of using Microsoft~\textit{WARP} may be.\\
\\
In conclusion; this study proposes, pursuant to the established performance of Microsoft~\textit{WARP}, that \textit{WARP}-technologies are feasable for extended use in applications - for purposes other than debugging and profiling. 

%In regards to the decreased performance of \textit{WARP}-accelerated kernels when utilizing shared memory; it is probable that...

% Speculate surrounding the hypothesis.
% The effect shared memory has on WARP.

% Summary
%	Vilken bakgrund, utmaning, ansats och resultat omfattar studien?
% Discussion
%	Vilka relaterade studier förhåller sig materialet till?
%	Vilka tvetydliga aspekter av studien kräver diskussion?

% CONCLUSION - FUTURE WORK
\subsection{Future~Work}
\label{sec:conclusion:futurework}
For the sake of brevity, the author suggests complementary elaboration into double precision calculations in \textit{DirectCompute}-kernels, with the intent of examining whether or not the Subjects detailed in Section~\ref{sec:contribution:Subjectofstudy} may have differentiating effects on computational precision.\\
\\
Additionally, the use of more complex kernels  in coagency with the \textit{WARP}-driver should be examined in order to study the effects of more demanding emulation on the \textit{CPU}.

% Answer and Oppertunity
%	Vilka fortsatta studier föreslår rapportens författare?

% ACKNOWLEDGMENTS
%\section*{Acknowledgments} % The \section*{} command stops section numbering
%\addcontentsline{toc}{section}{\hspace*{-\tocsep}Acknowledgments} % Adds this section to the table of contents with negative horizontal space equal to the indent for the numbered sections
%\label{sec:acknowledgments}
%I wish to express my gratitude to my fellow students, colleagues and close friends Bob, Benny and no-one for their work, co-operation and positive attitude throughout the execution of this experiment. 

\newpage
\section*{Appendix}
\addcontentsline{toc}{section}{\hspace*{-\tocsep}Acknowledgments} % Adds this section to the table of contents with negative horizontal space equal to the indent for the numbered sections
\label{sec:appendix}
\subsection*{Matrix~mult.~w.~Blocks}
\begin{lstlisting}
#ifndef DV2549_FXS_MULTFLOATBASIC_FX
#define DV2549_FXS_MULTFLOATBASIC_FX

#include <CommonFloat.fx>

[ numthreads( BLOCK_SIZE, BLOCK_SIZE, 1 ) ]
void main(
	uint3 tIdx : SV_GroupThreadID,
	uint3 bIdx : SV_GroupID ) {
	const uint row = bIdx.y * BLOCK_SIZE + tIdx.y;
	const uint col = bIdx.x * BLOCK_SIZE + tIdx.x;
	if( row >= cRows || col >= cCols ) {
		return;
	}
        
	float sum = 0;
	for( uint i = 0; i < aRows; i++ ) {
		uint idxA = row * aRows + i;
		uint idxB = col + bRows * i;
		sum += mA[ idxA ] * mB[ idxB ];
	}
	mC[ row * cRows + col ] = sum;
}

#endif // DV2549_FXS_MULTFLOATBASIC_FX
\end{lstlisting}

\subsection*{Matrix~mult.~w.~Blocks~\&~Shared~Memory}
\begin{lstlisting}
#ifndef DV2549_FXS_MULTFLOATTILE_H
#define DV2549_FXS_MULTFLOATTILE_H

#include <CommonFloat.fx>

groupshared float mAs[ BLOCK_SIZE ][ BLOCK_SIZE ];
groupshared float mBs[ BLOCK_SIZE ][ BLOCK_SIZE ];

[ numthreads( BLOCK_SIZE, BLOCK_SIZE, 1 ) ]
void main(
	uint3 tIdx : SV_GroupThreadID,
	uint3 bIdx : SV_GroupID ) {
	const uint row = bIdx.y * BLOCK_SIZE + tIdx.y;
	const uint col = bIdx.x * BLOCK_SIZE + tIdx.x;
	
	float sum = 0;
	const uint blocks = ceil( 
		(float)aRows / (float)BLOCK_SIZE );
	for( uint i = 0; i < blocks; i++ ) {
		mAs[ tIdx.y ][ tIdx.x ] = mA[ 
			row * aRows + ( i * BLOCK_SIZE + tIdx.x ) ];
		mBs[ tIdx.y ][ tIdx.x ] = mB[ 
			col + bRows * ( i * BLOCK_SIZE + tIdx.y ) ];
		GroupMemoryBarrierWithGroupSync();
        
		for( uint j = 0; j < BLOCK_SIZE; j++ ) {
			sum += 
				mAs[ tIdx.y ][ j ] * mBs[ j ][ tIdx.x ];
		}
		GroupMemoryBarrierWithGroupSync();
	}
	if( row >= cRows || col >= cCols ) {
		return;
	}
	mC[ row * cRows + col ] = sum;
}

#endif // DV2549_FXS_MULTFLOATTILE_H

\end{lstlisting}

\bibliographystyle{IEEEtranS}
\bibliography{article}
\end{document}

%\begin{table}[h]
%\begin{center}
%\begin{tabular}{l|r|r|}
%\cline{2-3}
%\multicolumn{1}{c}{\textit{INT}}    & \multicolumn{1}{|c|}{\textbf{BASIC}} & \multicolumn{1}{|c|}{\textbf{TILED}} \\ \hline
%\multicolumn{1}{|l|}{\textbf{HARD}} &                                      &                                      \\ \hline
%\multicolumn{1}{|l|}{\textbf{SOFT}} &                                      &                                      \\ \hline
%\multicolumn{3}{l}{}                                                                                              \\ \cline{2-3} 
%\multicolumn{1}{c}{\textit{FLOAT}}  & \multicolumn{1}{|c|}{\textbf{BASIC}} & \multicolumn{1}{|c|}{\textbf{TILED}} \\ \hline
%\multicolumn{1}{|l|}{\textbf{HARD}} &                                      &                                      \\ \hline
%\multicolumn{1}{|l|}{\textbf{SOFT}} &                                      &                                      \\ \hline
%\end{tabular}
%\end{center}
%\caption{-}
%\label{tab:conclusion:perc}
%\end{table}
